<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>刘朗鸣 (LIU Langming)</title>
</head>
<body>
<div id="layout-content">
<div id="toptitle">
<h1>刘朗鸣 (LIU Langming)</h1>
</div>
<table class="imgtable"><tr><td>
<a href="https://ming429778.github.io/"><img src="photo_blue.jpg" alt="alt text" width="180px" /></a>&nbsp;</td>
<td align="left"><p>PhD<br />
Data Science, School of DS</a>, <br />
<a href="http://www.cityu.edu.hk/">City University of Hong kong</a>, <br />
HongKong 999077, China <br />
Tel: +86 18810218320/+852 66618290  <br />
Email: langmiliu2-c@my.cityu.edu.hk, liulangming.llm@alibaba-inc.com <br />
<a href="https://scholar.google.com/citations?user=kfNSEdQAAAAJ&hl=en">[Google Scholar]</a> <br /> 
<br />
  
<!-- <a href="pdf/Aikun_Xu_CV.pdf">[我的简历]</a> <a href="https://scholar.google.com/citations?user=-dqI968AAAAJ&hl=zh-CN">[Google Scholar]</a> 
  <a href="https://github.com/xuaikun">[GitHub]<a href="EnHome.html">[English Page]</a></p> -->
  
</td></tr></table>
  
<h2>About Me</h2>  
<p>I am currently working in Taobao & Tmall Group of Alibaba as a senior algorithm engineer. </p>
<p>I earned my PhD in Data Science under the supervision of <a href="https://zhaoxyai.github.io/">Prof. Xiangyu Zhao</a>, 
  with <a href="https://www.sydney.edu.au/science/about/our-people/academic-staff/dingxuan-zhou.html">Prof. Dingxuan Zhou</a> as my co-supervisor. 
  I received my science bachelor's degree in 2020 from Beihang University, where I majored in Applied Mathematics.</p>  
<p>My research interests include Large Language Models, Recommendation Systems, Federated Learning, and Reinforcement Learning.</p>
  
<h2>Education Experience</h2>

 <table class="imgtable"><tr><td>
<a href="https://ming429778.github.io/"><img src="CityU.jpg" alt="CityU" width="80px" /></a>&nbsp;</td>
<td align="left"><h3>PhD: <a href="https://www.cityu.edu.hk/">City University of Hong Kong </a> (2020.9 ~ 2024.10)</h3>
<ul>
<li><p>Gruaduated from City University of Hong Kong (qs: 53)</p>
</li>
<li><p><b>School</b>: Data Science</p>
</li>
<li><p><b>GPA</b>: 4.05/4.3
</li>
 </ul>
</td></tr></table>
  
<table class="imgtable"><tr><td>
<a href="https://ming429778.github.io/"><img src="Beihang.jpg" alt="Beihang University" width="80px" /></a>&nbsp;</td>
<td align="left"><h3>Bachelor: <a href="https://www.buaa.edu.cn/">Beihang University </a> (2016.9 ~ 2020.7)</h3>
<ul>
<li><p>Gruaduated from Beihang University (985, 211)</p>
</li>
<li><p><b>School</b>: Mathematics and Applied Mathematices</p>
</li>
<li><p><b>GPA</b>: 3.5/4.0 
</li>
 </ul>
</td></tr></table>

<h2>Reseach Interests</h2>
<p><b>Large Language Models</b>: Pre-training, Efficiency, E-commerce Knowledge, and Downstream Application.</p> 
<p><b>Recommender Systems</b>: Sequential Recommendation, Efficiency, Linear Complexity, and Generative Recommendation.</p>  
<p><b>Federated Learning</b>: Convergence Theory, and Federated Recommendation.</p>  
<p><b>Reinforcement Learning</b>: Hallucination Optimization.</p>  
  
<h2>Publications</h2>
  
<ul>
<li><p>NEZHA: A Zero-sacrifice and Hyperspeed Decoding Architecture for Generative Recommendations.
<i>WWW, 2026 (CCF-A Conference, Accepted).  </i> <a href="https://arxiv.org/abs/2511.18793">https://arxiv.org/abs/2511.18793</a> </p>
</li>
<li><p>Unlocking Scaling Law in Industrial Recommendation Systems with a Three-step Paradigm based Large User Model.
<i>WSDM, 2026 (CCF-B Conference, Accepted).  </i> <a href="https://arxiv.org/abs/2502.08309">https://arxiv.org/abs/2502.08309</a> </p>
</li>
<li><p>How to inject knowledge efficiently? Knowledge Infusion Scaling Law for Pre-training Large Language Models.
<i>EMNLP, 2025 (CCF-B Conference, Accepted).  </i> <a href="https://arxiv.org/abs/2509.19371">https://arxiv.org/abs/2509.19371</a> </p>
</li>
<li><p>Benchmarking Large Language Models in E-commerce Leveraging Knowledge Graph.
<i>CIKM, 2025 (CCF-B Conference, Accepted).  </i> <a href="https://arxiv.org/abs/2503.15990">https://arxiv.org/abs/2503.15990</a> </p>
</li>
<li><p>ChineseEcomQA: A Scalable E-commerce Concept Evaluation Benchmark for Large Language Models.
<i>KDD, 2025 (CCF-A Conference, Accepted).  </i> <a href="https://arxiv.org/abs/2502.20196">https://arxiv.org/abs/2502.20196</a> </p>
</li>
<li><p>UQABench: Evaluating User Embedding for Prompting LLMs in Personalized Question Answering.
<i>KDD, 2025 (CCF-A Conference, Accepted).  </i> <a href="https://arxiv.org/abs/2502.19178">https://arxiv.org/abs/2502.19178</a> </p>
</li>
<li><p>Multi-task Offline Reinforcement Learning for Online Advertising in Recommender Systems.
<i>KDD, 2025 (CCF-A Conference, Accepted).  </i> <a href="https://arxiv.org/abs/2506.23090">https://arxiv.org/abs/2506.23090</a> </p>
</li>
<li><p>Efficient and Robust Regularized Federated Recommendation.
<i>CIKM, 2024 (CCF-B Conference, Accepted).  </i> <a href="https://arxiv.org/abs/2411.01540">https://arxiv.org/abs/2411.01540</a> </p>
</li>
<li><p>Analysis of Regularized Federated Learning.
<i>Neurocomputing (SCI-Q2 Journal, Accepted).  </i> <a href="https://arxiv.org/abs/2411.01548">https://arxiv.org/abs/2411.01548</a> </p>
</li>
<li><p>Deep Learning for Social Recommendation: A Survey.
<i>TOIS, 2023 (CCF-A Journal, Under Review). </i></p>
</li>
<li><p>LinRec: Linear Attention Mechanism for Long-term Sequential Recommender Systems.
<i>SIGIR, 2023 (CCF-A Conference, Accepted).  </i> <a href="https://arxiv.org/abs/2411.01537">https://arxiv.org/abs/2411.01537</a> </p>
</ul>

<div id="footer">
<div id="footer-text">
<br>Page generated 2022-10-08, by <a href="https://ming429778.github.io/">Liu Langming</a>.
</div>
</div>
</div>
</body>
</html>
